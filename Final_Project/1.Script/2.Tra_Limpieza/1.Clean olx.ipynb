{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Import Library's***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Load the data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 35 fields in line 591, saw 36\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-540a0c6bdc77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_origen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/RC/Desktop/DS4A_workspace/git/Team35/Grupo35-DS4A/Final_Project/1.Script/1.Ext_Web_Scraping/OLX/Data_result_web_scrapping/OLX_Data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2057\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2059\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2060\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 35 fields in line 591, saw 36\n"
     ]
    }
   ],
   "source": [
    "df_origen = pd.read_csv('C:/Users/RC/Desktop/DS4A_workspace/git/Team35/Grupo35-DS4A/Final_Project/1.Script/1.Ext_Web_Scraping/OLX/Data_result_web_scrapping/OLX_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Eliminar duplicados***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16553\n"
     ]
    }
   ],
   "source": [
    "train = df_origen.drop_duplicates().reset_index(drop=True)\n",
    "n_rows,n_columns =train.shape\n",
    "print(n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['Código web']=='100-M2504634'].to_csv('prueba2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Limpieza de NAN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count_null = train.isnull().sum().reset_index(name='q_nan')\n",
    "\n",
    "# Variable identificadas como no utiles\n",
    "columns_to_drop = ['Ancho','Características del Parqueadero','Con muebles','Depósitos','Fondo','Número de Ascensores',\n",
    "                   'Número de Closets','Número de líneas teléfonicas','Terraza/Balcón','Tipo de Cortinas',\n",
    "                   'Tipo de calentador','Tipo de estufa','Tipo de parqueadero','Tipo de piso en alcobas',\n",
    "                   'Tipo de piso en comedor','Tipo de piso en estudio','Tipo de piso en sala','Tipo instalación de gas',\n",
    "                   'Valor de arriendo','areaPrivada','businessTypeId','cityname','hdCompanyUrl','hdIsOcasional',\n",
    "                   'hdnBusinessType','nameProperty','nomBarrio','nombreEmpresa','propertyTypeId','valorArriendo',\n",
    "                   'Área Terraza/Balcón','Área privada','Habitaciones',\n",
    "                  'Área construida','Área del lote','Baños']\n",
    "\n",
    "#identifica los campos que tengan el 90% de sus \n",
    "for columns in data_count_null[data_count_null['q_nan']==(n_rows)]['index']:\n",
    "    columns_to_drop.append(columns)\n",
    "\n",
    "train = train.drop(columns_to_drop,axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Manejo de extras o complementos***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extra1: El campo viene con las descripciones de los compementos -- No se debe hacer cambios\n",
    "- Extra2: Contiene si o no, se debe tomar el nombre del campo como el atributo de complemento\n",
    "- Extra3: El campo contiene la descripción y dentro de la misma indica que tipo de extra es\n",
    "- Extra4: El campo contiene la descripción pero es necesario complementar la información con el nombre del campo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra2_descripcion = ['Ascensor','Cerca Centros Comerciales','Cerca Colegios / Universidades','Cerca Parques',\n",
    "                      'Cerca Supermercados','Cerca Transporte Público','Conjunto cerrado','Cuarto de servicio',\n",
    "                      'En interior y/o bloque','Esquinero','Estudio o biblioteca','Parqueadero cubierto',\n",
    "                      'Zona de BBQ','Zona de lavanderia']\n",
    "\n",
    "train_test['extra2'] = ''\n",
    "for extra2 in extra2_descripcion:\n",
    "    train_test[extra2] = train_test[extra2].apply(lambda x: extra2+',' if x == 'Si' else '')\n",
    "    train_test['extra2'] = train_test['extra2']+train_test[extra2]\n",
    "    #train_test = train_test.drop([extra2],axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra3_descripcion = ['Tipo comedor','Tipo de Casa','Tipo de acabado piso']\n",
    "\n",
    "train_test['extra3'] = ''\n",
    "for extra3 in extra3_descripcion:\n",
    "    train_test[extra3] = train_test[extra3].apply(lambda x: x+',' if x==x else '')\n",
    "    train_test['extra3'] = train_test['extra3']+train_test[extra3]\n",
    "    train_test = train_test.drop([extra3],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra4_descripcion = ['Tipo de Cocina','Vigilancia','Vista']\n",
    "\n",
    "train_test['extra4'] = ''\n",
    "for extra4 in extra4_descripcion:\n",
    "    \n",
    "    train_test[extra4] = train_test[extra4].apply(lambda x: extra4+' '+str(x)+',' if x==x else ' ')\n",
    "    train_test['extra4'] = train_test['extra4']+train_test[extra4]\n",
    "    train_test = train_test.drop([extra4],axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['extra'] = train_test['complemento']+train_test['extra2']+train_test['extra3']+train_test['extra4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_test.drop(['complemento','extra2','extra3','extra4'],axis='columns').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Homologacion de campos***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['Código web']=='100-M2504634'].to_csv('prueba2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Parqueadero\n",
      "['1.0' nan '2.0' '3.0' '4 o más' '2' '1' '3' '4+']\n",
      "**** numGaraje\n",
      "['1.0' '0.0' '2.0' '3.0' '4.0' nan '4+' '3' '2' '4' '0' '1']\n",
      "**** Código web\n",
      "['2571-M2012354' '920-42149736' '607-M2267033' ... '603-M2373742'\n",
      " '639-M4769' '9-2019050003']\n"
     ]
    }
   ],
   "source": [
    "x = ['Parqueadero','numGaraje','Código web']\n",
    "train[x].to_csv('prueba.csv')\n",
    "\n",
    "for y in x:\n",
    "    print(\"****\",y)\n",
    "    print(train[y].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homologacion_columns = {'Category1':'tipo_inueble',\n",
    "                        'Location3':'zona',\n",
    "                        'Nombre común del barrio':'barrio1', \n",
    "                        'Nombre del barrio catastral':'sector_catastral', \n",
    "                        'description':'descripcion', \n",
    "                        'Price':'precio',\n",
    "                        'ContractType':'tipo_contrato',\n",
    "                        'areaConstruida':'area', \n",
    "                        'Address':'direccion', \n",
    "                        'Rooms':'numero_habitaciones', \n",
    "                        'numBanos':'num_banos',\n",
    "                        'Tiempo de construido':'edad',\n",
    "                        'Condition':'condicion', \n",
    "                        'Floor': 'piso_ubicacion', \n",
    "                        'AdministrationPrice':'precio_administracion',\n",
    "                        'Estrato':'estrato',\n",
    "                        'Garages':'num_garages',\n",
    "                        'Extras':'extras', \n",
    "                        'latitude':'latitude',\n",
    "                        'longitude':'longitude',\n",
    "                        'InteriorFloors':'piso_interior',\n",
    "                        'Código web':'id_inmueble'}\n",
    "\n",
    "train = train.rename(columns = homologacion_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
